## 一、集合概述

### 1. Java容器有哪些？

Java 集合，也叫作**容器**，主要是由两大接口派生而来：

一类是 Collection 接口，主要用于存放单一元素，Collection 接口有三个主要的子接口：List、Set 和 Queue：

List: ArrayList, LinkedList

Set: HashSet, LinkedHashSet, TreeSet

Queue: PriorityQueue, DelayQueue, ArrayDeque

另一类是`Map`接口，主要用于存放键值对：

Map: HashMap, LinkedHashMap, Hashtable

### 2. 说说 List、Set、Map 三者的区别？三者的底层结构？

List：存储的元素是有序的、可重复的。

Set：存储的元素是无序的、不可重复的。

Queue：存储的元素是有序的、可重复的，但是**按特定的队列规则**来确定先后顺序（和`List`区别）。

Map：存储键值对，key 和 value 都是无序的，但是 key 不可以重复，value 可以重复



ArrayList：Object[] 数组，动态数组

LinkedList：双向链表



HashSet：基于HashMap实现，底层用 HashMap 保存元素；

LinkedHashSet：是HashSet 的子类，内部通过 LinkedHashMap 实现；

TreeSet：红黑树



HashMap：

1. JDK1.8 之前使用**数组+链表**
2. JDK1.8 之后使用**数组+链表+红黑树**

LinkedHashMap

Hashtable

TreeMap

### 3. (高频) Java 线程安全的集合类有哪些？

1. CopyOnWriteArrayList：

1. 底层数据结构是数组，适合读多写少
2. 读数据读的是**数组快照**，不会加锁，多个线程可以并发读取。
3. 写数数据会先复制出一个新的数组，然后用ReentrantLock加锁防止并发写，写完成后将引用指向新数组。

1. ConcurrentHashMap
2. CopyOnWriteArraySet

1. 底层数据结构基于CopyOnWriteArrayList
2. 读数据读的是**数组快照**，不会加锁，多个线程可以并发读取。
3. 写数数据会先复制出一个新的数组，然后用ReentrantLock加独占锁防止并发写，也不会影响读操作。
4. 唯一性保证：遍历内部数组，检查新元素是否已经存在

------

## 二、List

### 1. (高频) ArrayList和Array的区别？

Array是静态数组，ArrayList 底层基于动态数组实现，使用起来更灵活。

1. ArrayList 创建时不需要指定大小，而Array创建时必须指定大小。
2. ArrayList 中只能存储对象、包装类。Array可以直接存储基本类型数据，也可以存储对象。
3. ArrayList 支持插入、删除、遍历等常见操作，并且提供了丰富的 API。
   Array只是一个固定长度的数组，只能按照下标访问其中的元素，不具备动态添加、删除元素的能力。
4. ArrayList 许**使用泛型来确保类型安全**，Array不可以。

### 2. (中高频) ArrayList 和 LinkedList 的区别？

1. **底层数据结构**：ArrayList底层使用的是Object数组，LinkedList底层使用的是双向链表
2. **是否快速随机访问元素：
   **ArrayList支持，通过索引访问元素时间复杂度 O(1)；
   LinkedList不支持元素随机访问。
3. **插入和删除操作：
   **ArrayList 采用数组存储，如果在末尾插入，时间复杂度为 O(1)；如果是别的任意位置 i，平均时间复杂度为 O(n/2)，因为需要将位置 i 的后面 n-i 个元素后移一位。
   LinkedList 采用链表存储，在头尾插入或删除元素的时间复杂度为 O(1)；在指定位置 i 插入或删除元素的时间复杂度为 O(n)。

### 3. LinkedList为什么不能实现RandomAccess 接口？

RandomAccess是一个标记接口，**用来标明实现该接口的类支持快速随机访问**。由于LinkedList底层数据结构是链表，内存地址不连续，不能通过索引快速访问，所以不能实现RandomAccess接口。

标记接口：这个接口是做标记用的，内部并没有提供任何方法或者字段，向JVM或框架表明它具备某种能力或属性，从而对其分类并决定是否执行某些操作。

### 4. (中高频) ArrayList扩容机制？

1. 如果使用无参构造函数初始化，初始数组是一个空数组， 第一次添加元素会将容量扩到10。
2. 后面每次添加元素都会动态检查数组是否有足够容量，如果不够会扩容为原来的1.5倍作为新容量。
3. 如果新容量小于**添加新元素所需的最小容量**minCapacity数值（例如批量添加100），新容量设置为 minCapacity。

------

## 三、Set

### 1. HashSet 底层是如何进行比较的？

简而言之先hashCode，后equals

当把元素加入HashSet时，HashSet会**调用元素所属类的hashCode**，计算此对象的哈希值，哈希值决定了存放的位置。若此位置没有存储对象则直接存储，如果已有对象则**通过元素所属类的equals()比较两个对象是否相同**，相同则不能被添加，不同则添加。

### 2. 往 Set 中存自定义对象需要注意什么？

1. 重写 equals() 用于在两个元素位置相同的时候比较两个元素内容是否相等；
2. 重写hashCode() 确保内容相同的两个对象哈希值也相同，从而正确计算元素的存储位置；比如对象中有String类型的属性，就根据String计算哈希值

### 3. ⽐较 HashSet、LinkedHashSet 和TreeSet 三者的异同？

三者都是Set接口的实现类，都能保证元素唯一性，且都不是线程安全的。

**底层数据结构**不同：

1. HashSet 底层基于HashMap实现，元素的顺序是存储顺序
2. LinkedHashSet底层是双向链表+哈希表，元素的顺序是插入删除顺序
3. TreeSet 底层是红黑树，元素是有序的，排序方式有自然排序和定制排序。

**应用场景**不同：

1. HashSet 用于不需要保证元素插入取出顺序的场景。
2. LinkedHashSet 用于保证元素的插入和取出顺序满足**FIFO**的场景。
3. TreeSet 用于支持对元素进行自定义排序的场景。

------

## 四、Queue



------

## 五、Map（重要）

### 1. (中高频) 哈希冲突解决方案？

1. **拉链法**
2. **开放地址法**
   发生哈希冲突时通过探测其余空闲槽位来解决冲突

1. 线性探测：按照固定步长依次探测下一个槽位，直到找到空闲的
2. 二次探测：按照二次方步长进行探测
3. 双重散列：另一个哈希函数计算步长，避免固定步长带来的堆积现象

1. **再哈希法
   **用另一种哈希函数重新计算哈希值，直到找到空闲槽位
2. **动态扩容
   **容量达到阈值时，对哈希表容量进行动态扩容，重新计算元素哈希值并分配。

### 2. 说说你对 HashMap 的了解？（说一下 HashMap 的特点？）

1. HashMap主要用来存放键值对，基于哈希表的 Map 接口实现，存取是无序的，也是非线程安全的；
2. HashMap可以存储null值的 key和value，null作为键**只能有一个**，null作为值**可以有多个**；
3. JDK1.8之前HashMap由数组加链表组成的，数组是HashMap的主体，链表主要为了解决哈希冲突。 
   JDK1.8以后的HashMap在解决哈希冲突时有了较大的变化，当链表长度大于阈值 8 并且数组的长度大于等于 64，将链表转化为红黑树；树节点数量小于 6 时，红黑树退化为链表；
4. HashMap 底层数组默认**初始化大小为 16**，之后每次扩充容量**变为原来的 2 倍**。并且，HashMap **使用 2 的幂作为数组大小**。

### 3. HashMap 底层如果同时遍历和删除会发生什么？

因为HashMap需要通过迭代器进行遍历，但是迭代器的设计不支持在遍历时对集合进行结构性修改，当在遍历过程中直接删除元素时，**导致迭代器的状态与实际集合的状态不一致**，可能引发ConcurrentModificationException (并发修改异常)。

### 4. **(高频) Hashmap底层怎么实现的？**

***JDK1.8 之前\***

HashMap底层数据结构是数组+链表，数组中存放的是 Node 对象，Node 含有 hash, key, value, next 四个属性，链表用于解决哈希冲突。HashMap 将 key 的 hashCode 结果经过扰动函数处理过后得到 hash 值，然后通过 (n-1)&hash 判断当前元素存放的位置：

如果当前位置没有元素，则直接新建一个 node 插入。如果当前位置存在元素的话，就遍历以该元素为头节点的链表，如果存在相同的 key 直接覆盖，不同就用头插法。

***JDK1.8 之后\***

在映射位置已有元素但 key 值不相等的情况下，

1. 会先检查当前节点是否为红黑树节点，是则直接插入红黑树。否则遍历链表，如果有相同的就覆盖，如果不同就尾插法插在尾部；
2. 插入完后，如果当前链表长度大于阈值（默认为 8）时，且数组长度大于等于 64 的情况下，会执行转红黑树操作，否则执行 resize() 方法对数组**扩容**。

### 5. HashMap负载因子为什么设置为0.75？初始化临界值是12？

HashMap中的threshold是HashMap所能容纳键值对的最大值，计算公式为：

*threshold = length \* LoadFactory*

负载因子大小越趋近于 1：1. 存放的数据越密集，添加数据发生 hash 冲突概率更高；2. 链表长度更长，查询效率也会越降低。

负载因子大小越趋近于 0：数组中个存放的数据也就越少，空间利用率低，造成浪费。

0.75 是对空间和性能的平衡选择。

### 6. HashMap在JDK1.8以后为什么要转为红黑树？

每次遍历平均时间复杂度是O(n)。由于红黑树有自平衡的特点，可以防止不平衡情况的发生，所以可以始终将查询时间复杂度控制在**O(logn)**。当链表越来越长，O(n)和O(logn)的区别会很明显，所以为了提升查找性能，把链表转化为红黑树的形式。

### 7. HashMap链表转树的阈值为什么为8？

如果hashCode随机分布良好，红黑树这种结构是很少被用到的。理想情况下，桶中的节点数概率符合泊松分布，**链表长度为8的概率小于千万分之一**，此时链表的性能已经很差。所以在这种比较罕见和极端的情况下，才会把链表转变为红黑树。

### 8. HashMap为什么不一开始就用红黑树，反而经历一个转换过程？

树节点 TreeNodes 所占的内存空间比普通节点 Node 大，所以只有在桶包含足够多的节点时才使用树节点。

### 9. JDK1.8以后的HashMap为什么在红黑树节点小于6的时候退化为链表？

这个策略主要是在内存和性能之间取得一种平衡。

1. 因为红黑树需要更多的内存来存储**树结构**，**树节点相对于普通节点**会占用更多的内存；
2. 虽然红黑树搜索时间复杂度是O(logn)，而链表是O(n)。元素数量较少时，使用链表可以更高效地执行操作，而红黑树的维护和操作反而显得复杂。

### 10. (中高频) 说说HashMap的put方法执行过程？

定位到数组位置...

***JDK1.8 之前\***

① 如果定位到的数组位置没有元素就新建一个Node对象直接插入。

② 如果定位到的数组位置有元素，遍历以这个元素为头结点的链表，依次和插入的key比较，如果key相同就直接覆盖，不同就采用**头插法**插入元素。

***JDK1.8 之后\***

① 如果定位到的数组位置没有元素就新建一个Node对象插入。

② 如果定位到的数组位置有元素，就用该位置第一个节点p和要插入的key比较，如果key相同就直接覆盖，如果key不相同，就判断p是否是一个树节点，如果是就调用putTreeVal将元素加入到红黑树中。
如果不是，则遍历以这个元素为头结点的链表，依次和插入的key比较，如果key相同就直接覆盖，不同就采用尾插法插入元素。插入后会检查链表是否达到阈值，是否需要进行转红黑树的操作。

### 11. HashMap为什么JDK1.8之前采用头插法？而JDK1.8之后采用尾插法呢？

当多个线程同时插入时，头插法可能会发生**环形链表**，尾插法不会

### 12. HashMap 的数组长度为什么是 2 的幂次？

1. **加快哈希计算：**用 hash 和 n-1 进行 & 运算的结果，和 hash 对 n 进行取余操作的结果是相同的。但是 & 操作是位运算会更快。
2. **减少哈希冲突：**n 是偶数，n-1 最后一位就是 1，当用 hash 进行 & 操作时，二进制结果最后一位可能是 0，也可能是 1，这样充分保证了散列的均匀性。如果 n 是某个奇数，则有一半的空间会被浪费。

### 13. **(中高频) HashMap扩容机制？**

HashMap扩容的触发条件是，在插入新元素后，如果数量达到阈值会触发扩容，阈值为容量乘以负载因子

1. 创建一个新的桶数组，容量是原数组的 2 倍。
2. 将原数组中的元素重新计算hash得到新的下标位置，并分配到新的桶数组中。

ps：Java8中优化了rehash的方法，提高了扩容的效率，先根据hash函数计算出一个新的hash值

![img](https://cdn.nlark.com/yuque/0/2024/png/42782944/1724292677188-a8e27225-470d-49e6-95ee-788d1c06741f.png)

**Map map = new HashMap(50) 实际初始容量？**

计算得出 50 / 0.75 = 66.67。

找到大于等于 66.67 的最接近的 2 的幂次方是 64（2^6 = 64）。

HashMap 总是向上取最近的 2 的幂次方，所以实际容量是 128。

### 14. (高频) HashMap线程安全吗？如何解决？

HashMap线程不安全

1. 可以使用Hashtable，因为 Hashtable 内部方法基本经过synchronized修饰，可以保证同一时刻只有一个线程访问资源，但是多线程环境下性能较差。如果对性能有要求，不推荐。
2. 推荐使用ConcurrentHashMap，底层使用的是 synchronized + CAS 来实现，比较像性能优化且线程安全的HashMap，比Hashtable更好。

### 15. **(中高频) HashMap 和 Hashtable 的区别？**

1. **线程安全**：HashMap 是非线程安全的，Hashtable 是线程安全的, 因为 Hashtable 内部的方法基本都经过 synchronized 修饰
2. **性能效率：**因为 Hashtable 保证了线程安全，所以效率相较于 HashMap 要更低。
3. **null**：HashMap 可以存储 null 的 key 和 value，但 null 作为键只能有一个，null 作为值可以有多个；Hashtable 不允许有 null 键和 null 值，否则会抛出 NullPointerException
4. **初始容量和扩容机制不同：
   **① 如果不指定容量初始值，Hashtable 默认的初始大小为 11，之后每次扩充容量变为原来的 2n+1。HashMap 默认的初始化大小为 16。之后每次扩充容量变为原来的 2 倍。
   ② Hashtable 会直接使用给定的大小，而 HashMap 会将其扩充为 2 的幂次方大小。

### 16. HashMap和HashSet的区别？

HashSet继承于AbstractSet抽象类，实现了Set、Cloneable、java.io.Serializable接口。HashSet不允许集合中出现重复的值。HashSet底层其实就是HashMap，所有对HashSet的操作其实就是对HashMap的操作。所以HashSet也不保证集合的顺序。

------

## 六、ConcurrentHashMap

### 1. (中高频) ConcurrentHashMap 底层原理？

***JDK1.7及之前\***

ConcurrentHashMap 底层数据结构是**分段数组 + 链表**，分段数组指的一个哈希表被分成多个Segment，每个 Segment 由 HashEntry 数组加链表构成。Segment 继承可重入锁 ReentrantLock，也就每个段都有自己的锁。当多个线程访问不同段的数据时，可以并行进行，不会相互阻塞。

***JDK1.8\***

ConcurrentHashMap 底层数据结构 **Node 数组 + 链表/红黑树**，使用更细粒度CAS+分桶锁保证线程安全。实现细节是通过哈希值定位到桶后，如果桶为空表示当前位置可以写入数据，利用CAS尝试写入，失败则**自旋**保证成功；如果桶不为空，加 synchronized 只锁定当前链表或红黑二叉树的首节点。



补充：自旋本质上是一种**自旋锁**机制，即线程发现资源被占用（例如在使用 CAS 操作时，数据写入失败），它不会立刻放弃执行，而是通过反复尝试获取该资源，直到成功为止。

### 2. ConcurrentHashMap 和 Hashtable 的区别？

ConcurrentHashMap和Hashtable的区别主要体现在实现线程安全的方式上。

**首先两者的底层数据结构，**JDK1.7的 ConcurrentHashMap 底层采用**分段式数组 + 链表**实现，JDK1.8采用的数据结构跟HashMap1.8的结构一样，**Node数组+链表+红黑树**。Hashtable和JDK1.8之前的HashMap的底层数据结构类似，采用**数组+链表**的形式，数组是Hashtable的主体，链表则是主要为了解决哈希冲突。

**所以两者实现线程安全的方式是有差异的（重要）：**

- ***ConcurrentHashMap：***
  在JDK1.7，由于ConcurrentHashMap内部分成多个Setment数组，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据就不会存在锁竞争，提高并发性能。
  到了JDK1.8的时候，ConcurrentHashMap不再使用Segment的概念，而是直接用**Node数组+链表+红黑树**，并发控制使用`synchronized`+CAS来操作，看上去像是优化过且线程安全的HashMap。
- ***Hashtable(同一把锁)：*** 
  Hashtable使用`synchronized`来保证线程安全。当一个线程访问同步方法时，其他线程也访问同步方法就会进入阻塞或轮询状态，如使用put添加元素，另一个线程不能使用put添加元素，也不能使用get，竞争会越来越激烈，效率十分低下。️

### 3. **谈谈ConcurrentHashMap的扩容机制？** 

ConcurrentHashMap 的扩容机制通过多线程协作完成，通过创建一个新的哈希表，并将旧表的数据迁移到新表中完成的。在扩容过程中，ConcurrentHashMap 依然能够进行并发读写操作，保证了高效的并发性能。

### 4. Concurrenthashmap 怎么保证可见性？如果用 volatile 修饰，那么这个被修饰的共享字段是什么？

volatile修饰的字段

1. table Node<K, V>[] 数组即哈希表
2. nextTable 一个新的数组
3. sizectl 哈希表的初始化扩容等

### 5. ConcurrentHashMap所有方法都线程安全吗？

ConcurrentHashMap单个方法都是线程安全的

但是方法组合起来就不是线程安全的，举例来说：

```java
if (map.get(key) == null) {  // 检查是否存在
    map.put(key, value);     // 插入新值
}
```

在多线程环境下，两个线程可能同时检查 get(key)，都发现 key 不存在，于是都尝试插入 value，结果导致一个线程的插入被另一个线程覆盖。这种组合操作缺乏原子性。

### 6. ConcurrentHashMap的size()方法如何实现的？线程安全吗？

1. JDK1.7

1. 遍历所有的 Segment，并累加每个 Segment 的元素个数。
2. 为了防止高并发修改导致结果不准确，size() 会进行多次尝试，如果计算的结果保持稳定，则返回该值。

1. JDK1.8

1. 有基础计数器baseCount和分散计数槽counterCell
2. 高并发时不同线程会被分散到不同的counterCell，通过合并多个counterCell的值计数
3. 通过CAS操作保证多线程可以同时安全地进行修改、删除等修改操作，不需要加锁

------

## 七、场景题

### 1. Java里的集合用过吗，项目里是怎么用的

1. ConcurrentHashMap**
   **RPC中把注册信息存储在本地服务注册器
   点评项目中的本地标记
2. List
   消费端缓存
3. TreeMap
   实现一致性Hash
4. Set
   消费提供者端维护一个set，用于存储注册过的节点信息

### 2. ArrayList频繁扩容导致添加性能急剧下降如何处理？

1. 预估数据量，初始化时设置更大的容量
2. 批量添加，会减少扩容次数
3. 批量添加时使用ensureCapacity()预先扩容，用minCapacity作为新数组的容量